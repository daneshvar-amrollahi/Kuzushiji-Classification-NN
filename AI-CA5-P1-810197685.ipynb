{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Assignment #5 (Neural Networks)\n",
    "### Artificial Intelligence Course - Spring 2021\n",
    "### Daneshvar Amrollahi (810197685)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_df = pd.read_csv(\"dataset/train_images.csv\")\n",
    "train_images_df.drop(['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>165</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "      <td>94</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>247</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1   2   3   4   5  6  7  8    9  ...  774  775  776  777  778  \\\n",
       "0       0   0   0   0   0   0  0  0  0    0  ...   11    3   11    2    0   \n",
       "1       0   0   0   0   0   0  0  0  0    0  ...    0   23  165   36    0   \n",
       "2       0   0   0   0   0   0  0  0  0    0  ...    0    0    0    0    0   \n",
       "3      13  50  47  56  94  36  0  0  0    0  ...    0    0    0    0    0   \n",
       "4       0   0   0   0   0   0  0  0  0    0  ...    0    0    0    0    0   \n",
       "...    ..  ..  ..  ..  ..  .. .. .. ..  ...  ...  ...  ...  ...  ...  ...   \n",
       "59995   0   0   0   0   0   0  0  0  4  158  ...  255  247  196    0    0   \n",
       "59996   0   0   0   0   0   0  0  0  0    0  ...    0    0    0    0    0   \n",
       "59997   0   0   0   0   0   0  0  0  0    0  ...  255  255   76    0    0   \n",
       "59998   0   0   0   0   0   0  0  0  0    0  ...    0    0    0    0    0   \n",
       "59999   0   0   0   0   0   0  0  0  0    0  ...    0    0    0    0    0   \n",
       "\n",
       "       779  780  781  782  783  \n",
       "0        0    0    0    0    0  \n",
       "1        0    0    0    0    0  \n",
       "2        0    0    0    0    0  \n",
       "3        0    0    0    0    0  \n",
       "4        0    0    0    0    0  \n",
       "...    ...  ...  ...  ...  ...  \n",
       "59995    0    0    0    0    0  \n",
       "59996    0    0    0    0    0  \n",
       "59997    0    0    0    0    0  \n",
       "59998    0    0    0    0    0  \n",
       "59999    0    0    0    0    0  \n",
       "\n",
       "[60000 rows x 784 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_df = pd.read_csv(\"dataset/train_labels.csv\")\n",
    "train_labels_df.drop(['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "0         19\n",
       "1          7\n",
       "2          4\n",
       "3         15\n",
       "4         12\n",
       "...      ...\n",
       "59995     12\n",
       "59996     15\n",
       "59997      2\n",
       "59998      7\n",
       "59999     11\n",
       "\n",
       "[60000 rows x 1 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>218</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>213</td>\n",
       "      <td>253</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>203</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>143</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4   5    6    7    8    9  ...  774  775  776  777  778  \\\n",
       "0      0  0  0  0  0   0    0    0    0  147  ...   30    0    0    0    0   \n",
       "1      0  0  0  0  0   0    0    0    0    0  ...    0    0    0    0    0   \n",
       "2      0  0  0  0  0   0    0    0    3  100  ...    0    0    0    0    0   \n",
       "3      0  0  0  0  0  31  218   43    0    0  ...   20    0    0    0    0   \n",
       "4      0  0  0  0  0   0    9  213  253   97  ...    0    0    0    0    0   \n",
       "...   .. .. .. .. ..  ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "14995  0  0  0  0  0   0    0    0   50  182  ...   67    0    0    0    0   \n",
       "14996  0  0  0  0  0   0    0    0    0    0  ...  255  255  203   16    0   \n",
       "14997  0  0  0  0  0   0    0    3  143  254  ...    0    0    0    0    0   \n",
       "14998  0  0  0  0  0   0    0    0    0    0  ...    0    0    0    0    0   \n",
       "14999  0  0  0  0  0   0    0    0    0    0  ...    0    0    0    0    0   \n",
       "\n",
       "       779  780  781  782  783  \n",
       "0        0    0    0    0    0  \n",
       "1        0    0    0    0    0  \n",
       "2        0    0    0    0    0  \n",
       "3        0    0    0    0    0  \n",
       "4        0    0    0    0    0  \n",
       "...    ...  ...  ...  ...  ...  \n",
       "14995    0    0    0    0    0  \n",
       "14996    0    0    0    0    0  \n",
       "14997    0    0    0    0    0  \n",
       "14998    0    0    0    0    0  \n",
       "14999    0    0    0    0    0  \n",
       "\n",
       "[15000 rows x 784 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images_df = pd.read_csv(\"dataset/test_images.csv\")\n",
    "test_images_df.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "test_images_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_df = pd.read_csv(\"dataset/test_labels.csv\")\n",
    "test_labels_df.drop(['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_labels_df = train_labels_df.rename(columns={'0': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_labels_df = test_labels_df.rename(columns={'0': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index, counts = np.unique(test_labels_df['label'].values, return_counts = True)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0 ,0, 1, 1])\n",
    "ax.bar(index ,counts)\n",
    "\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.ylabel(\"Label Counts\")\n",
    "plt.title(\"Label Counts for Test Labels\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index, counts = np.unique(train_labels_df['label'].values, return_counts = True)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0 ,0, 1, 1])\n",
    "ax.bar(index ,counts)\n",
    "\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.ylabel(\"Label Counts\")\n",
    "plt.title(\"Label Counts for Train Labels\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "0         19\n",
       "1          7\n",
       "2          4\n",
       "3         15\n",
       "4         12\n",
       "...      ...\n",
       "59995     12\n",
       "59996     15\n",
       "59997      2\n",
       "59998      7\n",
       "59999     11\n",
       "\n",
       "[60000 rows x 1 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some random samples of the train dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixels = []\n",
    "tags = []\n",
    "\n",
    "for i in range(5):\n",
    "    row = train_images_df.iloc[[i]]\n",
    "    pixels.append(row)\n",
    "    \n",
    "tags = list(train_labels_df.head(10)[\"label\"]) \n",
    "\n",
    "    \n",
    "pixels = np.squeeze(pixels)\n",
    "\n",
    "for i in range(5):\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(pixels[i].reshape(28, 28))\n",
    "    fig.suptitle(f'label={tags[i]}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    result = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4         5         6         7         8  \\\n",
       "0      0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.011765   \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.121569  0.854902  0.168627  0.000000   \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.000000  0.035294  0.835294  0.992157   \n",
       "...    ...  ...  ...  ...  ...       ...       ...       ...       ...   \n",
       "14995  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.196078   \n",
       "14996  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "14997  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.011765  0.560784   \n",
       "14998  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "14999  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "              9  ...       774  775       776       777  778  779  780  781  \\\n",
       "0      0.576471  ...  0.117647  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0   \n",
       "1      0.000000  ...  0.000000  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0   \n",
       "2      0.392157  ...  0.000000  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0   \n",
       "3      0.000000  ...  0.078431  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0   \n",
       "4      0.380392  ...  0.000000  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0   \n",
       "...         ...  ...       ...  ...       ...       ...  ...  ...  ...  ...   \n",
       "14995  0.713725  ...  0.262745  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0   \n",
       "14996  0.000000  ...  1.000000  1.0  0.796078  0.062745  0.0  0.0  0.0  0.0   \n",
       "14997  0.996078  ...  0.000000  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0   \n",
       "14998  0.000000  ...  0.000000  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0   \n",
       "14999  0.000000  ...  0.000000  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       782  783  \n",
       "0      0.0  0.0  \n",
       "1      0.0  0.0  \n",
       "2      0.0  0.0  \n",
       "3      0.0  0.0  \n",
       "4      0.0  0.0  \n",
       "...    ...  ...  \n",
       "14995  0.0  0.0  \n",
       "14996  0.0  0.0  \n",
       "14997  0.0  0.0  \n",
       "14998  0.0  0.0  \n",
       "14999  0.0  0.0  \n",
       "\n",
       "[15000 rows x 784 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images_df = normalize(test_images_df)\n",
    "test_images_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05098</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.219608</td>\n",
       "      <td>0.368627</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.619608</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968627</td>\n",
       "      <td>0.768627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5    6    7  \\\n",
       "0      0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0   \n",
       "1      0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0   \n",
       "2      0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0   \n",
       "3      0.05098  0.196078  0.184314  0.219608  0.368627  0.141176  0.0  0.0   \n",
       "4      0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0   \n",
       "...        ...       ...       ...       ...       ...       ...  ...  ...   \n",
       "59995  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0   \n",
       "59996  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0   \n",
       "59997  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0   \n",
       "59998  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0   \n",
       "59999  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0   \n",
       "\n",
       "              8         9  ...       774       775       776       777  778  \\\n",
       "0      0.000000  0.000000  ...  0.043137  0.011765  0.043137  0.007843  0.0   \n",
       "1      0.000000  0.000000  ...  0.000000  0.090196  0.647059  0.141176  0.0   \n",
       "2      0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "3      0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "4      0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "...         ...       ...  ...       ...       ...       ...       ...  ...   \n",
       "59995  0.015686  0.619608  ...  1.000000  0.968627  0.768627  0.000000  0.0   \n",
       "59996  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "59997  0.000000  0.000000  ...  1.000000  1.000000  0.298039  0.000000  0.0   \n",
       "59998  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "59999  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "\n",
       "       779  780  781  782  783  \n",
       "0      0.0  0.0  0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  0.0  0.0  \n",
       "3      0.0  0.0  0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  \n",
       "59995  0.0  0.0  0.0  0.0  0.0  \n",
       "59996  0.0  0.0  0.0  0.0  0.0  \n",
       "59997  0.0  0.0  0.0  0.0  0.0  \n",
       "59998  0.0  0.0  0.0  0.0  0.0  \n",
       "59999  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[60000 rows x 784 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_df = normalize(train_images_df)\n",
    "train_images_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    \n",
    "    def __init__(self, data, labels, n_classes, batch_size=None, shuffle=False):\n",
    "\n",
    "        assert len(data)==len(labels)\n",
    "        self.__n_classes = n_classes\n",
    "        self.__batch_size = batch_size\n",
    "        self.__shuffle = shuffle\n",
    "        self.__data = data\n",
    "        self.onehot_labels = self.__onehot(labels, self.__n_classes)\n",
    "        \n",
    "    def __onehot(self, labels, n_classes):\n",
    "        onehot_vectors = []\n",
    "        for label in labels:\n",
    "            cur = [0] * n_classes\n",
    "            cur[int(label[0])] = 1\n",
    "            onehot_vectors.append(cur)\n",
    "        \n",
    "        return onehot_vectors\n",
    "    \n",
    "    def __shuffle_dataset(self):\n",
    "        pass\n",
    "        # TODO: Implement\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \n",
    "        if self.__shuffle:\n",
    "            self.__shuffle_dataset()\n",
    "            \n",
    "        if self.__batch_size==None:\n",
    "            yield (np.matrix(self.__data), np.matrix(self.onehot_labels))\n",
    "            return\n",
    "            \n",
    "        for idx in range(0, len(self.__data), self.__batch_size):\n",
    "            yield (np.matrix(self.__data[idx:idx+self.__batch_size]), \n",
    "                   np.matrix(self.onehot_labels[idx:idx+self.__batch_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` \n",
    "for batch in trainloader:\n",
    "    batch[0] is a matrix with BATH_SIZE rows and 784 columns. Each row is an image.\n",
    "\n",
    "    batch[1] is a matrix with 20 columns and BATCH_SIZE rows. Each row is the one_hot vector\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "class Identical:\n",
    "    \n",
    "    def __init__(self): pass\n",
    "    \n",
    "    def __val(self, matrix):\n",
    "        identical_value = np.matrix(matrix, dtype=float)\n",
    "        return identical_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        temp = np.matrix(matrix, dtype=float)\n",
    "        identical_derivative = np.matrix(np.full(np.shape(temp), 1.))\n",
    "        return identical_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n",
    "    \n",
    "\n",
    "    \n",
    "class Relu:\n",
    "    \n",
    "    def __init__(self): pass\n",
    "    \n",
    "    def __val(self, matrix):\n",
    "        relu_value = np.array([np.array(x, copy=True) for x in matrix])\n",
    "        relu_value[relu_value < 0] = 0\n",
    "        return relu_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        relu_derivative = np.array([np.array(x, copy=True) for x in matrix])\n",
    "        relu_derivative[relu_derivative < 0] = 0\n",
    "        relu_derivative[relu_derivative > 0] = 1\n",
    "        return relu_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n",
    "\n",
    "\n",
    "    \n",
    "class LeakyRelu:\n",
    "    \n",
    "    def __init__(self, negative_slope=0.01):\n",
    "        self.negative_slope = 0.01\n",
    "    \n",
    "    def __val(self, matrix):\n",
    "        leacky_relu_value = np.array([np.array(x, copy=True) for x in matrix])\n",
    "        return np.where(leacky_relu_value > 0, leacky_relu_value, leacky_relu_value * 0.01)       \n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        leacky_relu_derivative = np.array([np.array(x, copy=True) for x in matrix])\n",
    "        return np.where(leacky_relu_derivative > 0, 1, 0.01)  \n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n",
    "\n",
    "    \n",
    "class Sigmoid:\n",
    "    \n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __val(self, matrix):\n",
    "        return 1.0 / (1.0 + np.exp(-matrix))\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        sigmoid_value = self.__val(matrix)\n",
    "        sigmoid_derivative = np.multiply(sigmoid_value, 1 - sigmoid_value)\n",
    "        return sigmoid_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n",
    "\n",
    "\n",
    "class Softmax:\n",
    "    \n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __val(self, matrix, axis = -1):\n",
    "    \n",
    "        softmax_value = np.zeros(matrix.shape)\n",
    "        for i in range(len(matrix)):\n",
    "            softmax_value[i] = np.exp(matrix[i] - np.max(matrix[i]))\n",
    "            softmax_value[i] = softmax_value[i] / np.sum(softmax_value[i])\n",
    "        return softmax_value\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n",
    "    \n",
    "class Tanh:\n",
    "    \n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __val(self, matrix):\n",
    "        return np.tanh(matrix)\n",
    "        #return (np.exp(matrix) - np.exp(-matrix)) / (np.exp(matrix) + np.exp(-matrix))\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        return 1 - np.multiply(matrix, matrix)\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions Correctness Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = np.linspace(-np.pi, np.pi, 12)\n",
    "tanh = Tanh()\n",
    "ans = tanh(test)\n",
    "\n",
    "plt.plot(test, ans, color = 'red', marker = \"o\")\n",
    "plt.title(\"my Tanh\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.show()\n",
    "\n",
    "ans = tanh.derivative(test)\n",
    "plt.plot(test, ans, color = 'red', marker = \"o\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1  2 -3]\n",
      " [ 4 -5  6]]\n",
      "\n",
      "[[0 2 0]\n",
      " [4 0 6]]\n",
      "[[0 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "[[0.26894142 0.88079708 0.04742587]\n",
      " [0.98201379 0.00669285 0.99752738]]\n",
      "[[0.19661193 0.10499359 0.04517666]\n",
      " [0.01766271 0.00664806 0.00246651]]\n",
      "\n",
      "[[-0.01  2.   -0.03]\n",
      " [ 4.   -0.05  6.  ]]\n",
      "[[0.01 1.   0.01]\n",
      " [1.   0.01 1.  ]]\n"
     ]
    }
   ],
   "source": [
    "test = np.array([[-1, 2, -3], [4, -5, 6]])\n",
    "print(test)\n",
    "\n",
    "print()\n",
    "relu = Relu()\n",
    "print(relu(test))\n",
    "print(relu.derivative(test))\n",
    "\n",
    "print()\n",
    "sigmoid = Sigmoid()\n",
    "print(sigmoid(test))\n",
    "print(sigmoid.derivative(test))\n",
    "\n",
    "print()\n",
    "leakyRelu =  LeakyRelu()\n",
    "print(leakyRelu(test))\n",
    "print(leakyRelu.derivative(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy: \n",
    "    \n",
    "    EPS = 1e-50\n",
    "    \n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __val(self, true_val, expected_val):\n",
    "        assert np.shape(true_val)==np.shape(expected_val)\n",
    "        softmax = Softmax()\n",
    "        \n",
    "        \n",
    "        cross_entropy_value = np.multiply(-expected_val, np.log(np.clip(softmax(true_val), self.EPS, 1 - self.EPS))).sum(axis = 1) \n",
    "        return cross_entropy_value\n",
    "        \n",
    "    def derivative(self, true_val, expected_val):\n",
    "        assert np.shape(true_val)==np.shape(expected_val)\n",
    "        softmax = Softmax()\n",
    "        \n",
    "        return softmax(true_val + self.EPS) - expected_val\n",
    "    \n",
    "    def __call__(self, true_val, expected_val):\n",
    "        return self.__val(true_val, expected_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy Correctness Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115.12925465]\n",
      "[0.]\n",
      "[0.55144471 1.55144471 1.05144471]\n"
     ]
    }
   ],
   "source": [
    "crossEntropy = CrossEntropy()\n",
    "\n",
    "predicted = np.array([[12345, 67890, 99]])\n",
    "ans = np.array([[0, 0, 1]])\n",
    "\n",
    "print(crossEntropy(predicted, ans))\n",
    "\n",
    "predicted = np.array([[12345, 67890, 99999999]])\n",
    "print(crossEntropy(predicted, ans))\n",
    "\n",
    "\n",
    "print(crossEntropy(np.array([[0, 0, 1], [1, 0, 0], [1, 0, 0]]), np.array([[0, 0, 1], [0, 0, 1], [0.5, 0.5, 0]])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Layer:\n",
    "\n",
    "    DEFAULT_LOW, DEFAULT_HIGH, DEFAULT_MEAN, DEFAULT_VAR = 0, 0.05, 0., 1.\n",
    "  \n",
    "    def __init__(self, input_size, output_size, \n",
    "                 activation=Identical(), initial_weight='uniform', **initializing_parameters):\n",
    "        \n",
    "        assert type(initial_weight)==str, 'Undefined activation function!'\n",
    "        \n",
    "        self.__weight_initializer_dict = {'uniform':self.__uniform_weight, 'normal':self.__normal_weight}\n",
    "        \n",
    "        assert initial_weight in self.__weight_initializer_dict, 'Undefined weight initialization function!'\n",
    "\n",
    "\n",
    "        self.__n_neurons = output_size\n",
    "        weight_initializer = self.__weight_initializer_dict[initial_weight]\n",
    "        self.__weight = weight_initializer(input_size, self.__n_neurons, **initializing_parameters)\n",
    "        self.__bias = weight_initializer(1, self.__n_neurons, **initializing_parameters)\n",
    "        self.__activation = activation\n",
    "        \n",
    "        self.__last_input = None\n",
    "        self.__last_activation_input = None\n",
    "        self.__last_activation_output = None\n",
    "        self.__last_activation_derivative = None\n",
    "        \n",
    "    def forward(self, layer_input):\n",
    "        assert np.ndim(layer_input)==2\n",
    "        assert np.size(self.__weight,0) == np.size(layer_input,1)\n",
    "        \n",
    "        self.__last_input = layer_input\n",
    "        self.__last_activation_input =  layer_input @ self.weight + self.bias\n",
    "        self.__last_activation_output = self.activation(self.__last_activation_input)\n",
    "        self.__last_activation_derivative = np.squeeze(self.activation.derivative(self.__last_activation_input))\n",
    "        \n",
    "        \n",
    "        return self.__last_activation_output\n",
    "    \n",
    "    def update_weights(self, backprop_tensor, lr):\n",
    "        \n",
    "        backprop_tensor = np.squeeze(backprop_tensor)\n",
    "        \n",
    "        \n",
    "        assert np.ndim(backprop_tensor)==2\n",
    "        assert np.size(backprop_tensor,0) == np.size(self.__last_activation_derivative,0)\n",
    "        assert np.size(backprop_tensor,1) == self.__n_neurons\n",
    "        \n",
    "        \n",
    "        xt = self.__last_input.transpose()\n",
    "        \n",
    "        yp = np.multiply(backprop_tensor, self.__last_activation_derivative)\n",
    "        \n",
    "        bt = np.matrix(np.tile(1, (1, yp.shape[0])))\n",
    "        \n",
    "\n",
    "        wp = np.matmul(xt, yp)\n",
    "        bp = np.matmul(bt, yp)\n",
    "        \n",
    "        backprop_tensor = np.matmul(yp, self.__weight.transpose())\n",
    "        \n",
    "        self.__weight -= wp * lr\n",
    "        self.__bias -= bp * lr\n",
    "        \n",
    "        \n",
    "        return backprop_tensor\n",
    "\n",
    "    def __uniform_weight(self, dim1, dim2, **initializing_parameters):\n",
    "        low, high = self.DEFAULT_LOW, self.DEFAULT_HIGH\n",
    "        if 'low' in initializing_parameters.keys(): low = initializing_parameters['low']\n",
    "        if 'high' in initializing_parameters.keys(): high = initializing_parameters['high']\n",
    "\n",
    "        weights = np.random.uniform(low = low, high = high, size = (dim1, dim2))\n",
    "\n",
    "        return weights\n",
    "\n",
    "    def __normal_weight(self, dim1, dim2, **initializing_parameters):\n",
    "        mean, var = self.DEFAULT_MEAN, self.DEFAULT_VAR\n",
    "        if 'mean' in initializing_parameters.keys(): mean = initializing_parameters['mean']\n",
    "        if 'var' in initializing_parameters.keys(): var = initializing_parameters['var']\n",
    "            \n",
    "            \n",
    "        weights = np.random.normal(loc = mean, scale = math.sqrt(var), size=(dim1, dim2))\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    @property\n",
    "    def n_neurons(self): return self.__n_neurons\n",
    "    \n",
    "    @property\n",
    "    def weight(self): return self.__weight\n",
    "    \n",
    "    @property\n",
    "    def bias(self): return self.__bias\n",
    "    \n",
    "    @property\n",
    "    def activation(self): return self.__activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN:\n",
    "    \n",
    "    def __init__(self, input_shape):\n",
    "        \n",
    "        self.__input_shape = input_shape\n",
    "        self.__output_shape = None\n",
    "        \n",
    "        self.__layers_list = []\n",
    "        \n",
    "        self.__lr = None\n",
    "        self.__loss = None\n",
    "\n",
    "        \n",
    "    def add_layer(self, n_neurons, activation=Relu(), initial_weight='uniform', **initializing_parameters):\n",
    "         \n",
    "        assert type(n_neurons)==int, \"Invalid number of neurons for the layer!\"\n",
    "        assert n_neurons>0, \"Invalid number of neurons for the layer!\"\n",
    "        \n",
    "        n_prev_neurons = self.__input_shape if len(self.__layers_list)==0 else self.__layers_list[-1].n_neurons\n",
    "        \n",
    "        new_layer = Layer(n_prev_neurons, n_neurons, activation, initial_weight, **initializing_parameters)\n",
    "        \n",
    "        \n",
    "        self.__layers_list.append(new_layer)\n",
    "        \n",
    "        self.__output_shape = self.__layers_list[-1].n_neurons \n",
    "      \n",
    "    \n",
    "    def set_training_param(self, loss=CrossEntropy(), learning_rate = 1e-3):\n",
    "        assert self.__layers_list, \"Uncomplete model!\"\n",
    "        self.__loss = loss\n",
    "        self.__lr = learning_rate\n",
    "    \n",
    "    \n",
    "    def forward(self, network_input):\n",
    "        assert type(self.__output_shape) != None, \"Model is not compiled!\"\n",
    "        \n",
    "        network_output = deepcopy(network_input)\n",
    "        \n",
    "        for layer in self.__layers_list:\n",
    "            network_output = layer.forward(network_output)\n",
    "            network_output = np.squeeze(network_output)\n",
    "            \n",
    "    \n",
    "        return network_output\n",
    "    \n",
    "    \n",
    "    def fit(self, epochs, trainloader, testloader=None, print_results=True):\n",
    "        \n",
    "        assert type(self.__output_shape) != None, \"Model is not compiled!\"\n",
    "        assert type(self.__lr) != None and type(self.__loss) != None, \"Training paramenters are not set!\"\n",
    "\n",
    "        log = {\"train_accuracy\":[], \"train_loss\":[], \"test_accuracy\":[], \"test_loss\":[]}\n",
    "        \n",
    "        for epoch in range(1, epochs+1):\n",
    "            \n",
    "            if print_results: \n",
    "                print('Epoch {}:'.format(epoch)) \n",
    "                \n",
    "            average_accuracy, average_loss = self.__train(trainloader)\n",
    "            log['train_accuracy'].append(average_accuracy)\n",
    "            log['train_loss'].append(average_loss)\n",
    "            if print_results:\n",
    "                print('\\tTrain: Average Accuracy: {}\\tAverage Loss: {}'.format(average_accuracy, average_loss))\n",
    "            \n",
    "            if type(testloader) != type(None):\n",
    "                average_accuracy, average_loss = self.__test(testloader)\n",
    "                log['test_accuracy'].append(average_accuracy)\n",
    "                log['test_loss'].append(average_loss)\n",
    "                if print_results:\n",
    "                    print('\\tTest: Average Accuracy: {}\\tAverage Loss: {}'.format(average_accuracy, average_loss))\n",
    "                    \n",
    "        return log\n",
    "    \n",
    "    \n",
    "    def __train(self, trainloader):\n",
    "        bach_accuracies, batch_losses = [], []\n",
    "        for x_train, y_train in trainloader:\n",
    "            batch_accuracy, batch_loss = self.__train_on_batch(x_train, y_train)\n",
    "            bach_accuracies.append(batch_accuracy)\n",
    "            batch_losses.append(batch_loss)\n",
    "        return np.mean(bach_accuracies), np.mean(batch_losses)\n",
    "    \n",
    "    \n",
    "    def __test(self, testloader):\n",
    "        bach_accuracies, batch_losses = [], []\n",
    "        for x_test, y_test in testloader:\n",
    "            batch_accuracy, batch_loss = self.__test_on_batch(x_test, y_test)\n",
    "            bach_accuracies.append(batch_accuracy)\n",
    "            batch_losses.append(batch_loss)\n",
    "        return np.mean(bach_accuracies), np.mean(batch_losses)\n",
    "\n",
    "    \n",
    "    def __train_on_batch(self, x_batch, y_batch):\n",
    "        \n",
    "        output_batch = self.forward(x_batch)\n",
    "        \n",
    "        batch_accuracy = self.__compute_accuracy(output_batch, y_batch)\n",
    "        \n",
    "        batch_average_loss = self.__update_weights(output_batch, y_batch)\n",
    "        \n",
    "        return (batch_accuracy, batch_average_loss)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __test_on_batch(self, x_batch, y_batch):\n",
    "        output_batch = self.forward(x_batch)\n",
    "        \n",
    "        cross_entropy = CrossEntropy()\n",
    "        batch_average_loss = np.sum(cross_entropy(output_batch, y_batch)) / len(output_batch)\n",
    "        \n",
    "        batch_accuracy = self.__compute_accuracy(output_batch, y_batch)\n",
    "        \n",
    "        return (batch_accuracy, batch_average_loss)\n",
    "            \n",
    "        \n",
    "    def __get_labels(self, outputs):\n",
    "        labels = np.argmax(outputs, axis = 1)\n",
    "        return labels\n",
    "    \n",
    "    \n",
    "    def __compute_accuracy(self, output, expected_output):\n",
    "        \n",
    "        labels = self.__get_labels(output)\n",
    "    \n",
    "        correct = 0\n",
    "        for i in range(len(output)):\n",
    "            \n",
    "            if (expected_output[i, labels[i]] == 1):\n",
    "                correct += 1\n",
    "                \n",
    "        return correct / len(output)\n",
    "    \n",
    "    \n",
    "    def __update_weights(self, output, y_train):\n",
    "        crossEntropy = CrossEntropy()\n",
    "        \n",
    "        d = crossEntropy.derivative(output, y_train)\n",
    "        for layer in reversed(self.__layers_list):\n",
    "             d = layer.update_weights(d, self.__lr)\n",
    "            \n",
    "        return np.sum(crossEntropy(output, y_train)) / len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "x = train_labels_df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "[[19], [7], [4], [15], [12], [13], [10], [0], [19], [2]]\n"
     ]
    }
   ],
   "source": [
    "print(len(x))\n",
    "print(x[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINLOADER = Dataloader(data = train_images_df.values.tolist(), labels = train_labels_df.values.tolist(), n_classes = 20, batch_size = BATCH_SIZE, shuffle = False)\n",
    "TESTLOADER = Dataloader(data = test_images_df.values.tolist(), labels = test_labels_df.values.tolist(), n_classes = 20, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Run:\n",
    "\n",
    "**EPOCHS**: 20\n",
    "\n",
    "**Layers**:\n",
    "\n",
    "|              | neurons     | activation |init weights|\n",
    "| -----------  | ----------- |------------|------------|\n",
    "| Input        | 784         | Relu       |Uniform     | \n",
    "| Hidden 1     | 16          |     Relu   |     Uniform|\n",
    "| Hidden 2     |   16        |  Relu      |     Uniform|\n",
    "| Output       |   20        |Identical   |     Uniform|\n",
    "\n",
    "**LEARNING_RATE** = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.15644989339019189\tAverage Loss: 2.6007119275178874\n",
      "\tTest: Average Accuracy: 0.2059397163120567\tAverage Loss: 2.369140937581629\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.4709321695095949\tAverage Loss: 1.7048972144246761\n",
      "\tTest: Average Accuracy: 0.474468085106383\tAverage Loss: 1.7884312247546057\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.6535847547974414\tAverage Loss: 1.1738468248538305\n",
      "\tTest: Average Accuracy: 0.5911347517730497\tAverage Loss: 1.4190390901368641\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.7281283315565032\tAverage Loss: 0.9442602021855095\n",
      "\tTest: Average Accuracy: 0.6457890070921987\tAverage Loss: 1.2624149982456228\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.7677405383795309\tAverage Loss: 0.8148377140196627\n",
      "\tTest: Average Accuracy: 0.6796099290780141\tAverage Loss: 1.1690310118172154\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.7922607942430704\tAverage Loss: 0.7317432082617603\n",
      "\tTest: Average Accuracy: 0.6931515957446809\tAverage Loss: 1.1176221559751969\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.8053871268656716\tAverage Loss: 0.6838787485028588\n",
      "\tTest: Average Accuracy: 0.7017508865248226\tAverage Loss: 1.084868887367028\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.8137326759061834\tAverage Loss: 0.6518637741894826\n",
      "\tTest: Average Accuracy: 0.707668439716312\tAverage Loss: 1.0610609876735349\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.8196961620469083\tAverage Loss: 0.6269264626800651\n",
      "\tTest: Average Accuracy: 0.7125886524822694\tAverage Loss: 1.044861870642415\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.8252098880597015\tAverage Loss: 0.6074973997755859\n",
      "\tTest: Average Accuracy: 0.7173093971631205\tAverage Loss: 1.0293857423451822\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.8298074360341151\tAverage Loss: 0.5930681489050634\n",
      "\tTest: Average Accuracy: 0.7194370567375886\tAverage Loss: 1.0241256767658038\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.8332555970149254\tAverage Loss: 0.5811932457062763\n",
      "\tTest: Average Accuracy: 0.7212765957446808\tAverage Loss: 1.02025647290589\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.8355710287846482\tAverage Loss: 0.5709028527771846\n",
      "\tTest: Average Accuracy: 0.7228058510638298\tAverage Loss: 1.014158364081477\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.8385194562899787\tAverage Loss: 0.5625012728584433\n",
      "\tTest: Average Accuracy: 0.7236702127659574\tAverage Loss: 1.0118827882691965\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.8406016791044776\tAverage Loss: 0.5551878787811892\n",
      "\tTest: Average Accuracy: 0.7238696808510638\tAverage Loss: 1.0092727084055497\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.8430503731343284\tAverage Loss: 0.5488493751339525\n",
      "\tTest: Average Accuracy: 0.7249335106382979\tAverage Loss: 1.0089067313170728\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.8450159914712153\tAverage Loss: 0.5433837656465043\n",
      "\tTest: Average Accuracy: 0.7264184397163119\tAverage Loss: 1.0077640260177727\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.8458488805970149\tAverage Loss: 0.53825184113275\n",
      "\tTest: Average Accuracy: 0.7290115248226949\tAverage Loss: 1.0066674039210788\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.8478644722814499\tAverage Loss: 0.5335611100897696\n",
      "\tTest: Average Accuracy: 0.7291223404255319\tAverage Loss: 1.0113720462867013\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.8488472814498934\tAverage Loss: 0.5292402522022959\n",
      "\tTest: Average Accuracy: 0.7297429078014184\tAverage Loss: 1.0122155111687385\n"
     ]
    }
   ],
   "source": [
    "# Sample code for building and training a model\n",
    "\n",
    "INPUT_SHAPE = 784\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "\n",
    "\n",
    "network.add_layer(n_neurons = 16, activation = Relu(), weight_initializer='uniform')\n",
    "\n",
    "network.add_layer(n_neurons = 16, activation = Relu(), weight_initializer='uniform')\n",
    "\n",
    "network.add_layer(n_neurons = 20, activation = Identical(), weight_initializer='uniform')\n",
    "\n",
    "network.set_training_param(loss=CrossEntropy(), learning_rate=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What would happen if all weights were initially set to 0?\n",
    "\n",
    "If all the weights are initialized to zeros, the derivatives will remain same. As a result, neurons will learn same features in each iterations. This problem is known as network failing to break symmetry. And not only zero, any constant initialization will produce a poor result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Too High Learning Rate Impact:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we test the network's output with **Learning Rate = 0.01** which is 10 times more than the previous one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.2921608475479744\tAverage Loss: 2.2407592185092216\n",
      "\tTest: Average Accuracy: 0.3351285460992908\tAverage Loss: 2.1868145000236594\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.38892590618336886\tAverage Loss: 1.85814489348723\n",
      "\tTest: Average Accuracy: 0.3593306737588653\tAverage Loss: 2.0200096185938516\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.4075826226012793\tAverage Loss: 1.8403739505434522\n",
      "\tTest: Average Accuracy: 0.3406693262411347\tAverage Loss: 2.2612666777062627\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.4250066631130064\tAverage Loss: 1.8166233895217667\n",
      "\tTest: Average Accuracy: 0.33260195035461\tAverage Loss: 2.170399926458565\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.3949060501066098\tAverage Loss: 1.8776600744987066\n",
      "\tTest: Average Accuracy: 0.33519503546099294\tAverage Loss: 2.1645849035885294\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.3663879264392324\tAverage Loss: 1.919330675071812\n",
      "\tTest: Average Accuracy: 0.27969858156028365\tAverage Loss: 2.243548452933924\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.39457289445628996\tAverage Loss: 1.8228077496720796\n",
      "\tTest: Average Accuracy: 0.3321808510638298\tAverage Loss: 2.1882344374164684\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.3091018123667377\tAverage Loss: 2.081645997111488\n",
      "\tTest: Average Accuracy: 0.24519060283687946\tAverage Loss: 2.3050040605809965\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.2980577025586354\tAverage Loss: 2.0642344503241192\n",
      "\tTest: Average Accuracy: 0.2634751773049645\tAverage Loss: 2.2583054110272003\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.31611473880597013\tAverage Loss: 2.011136141990022\n",
      "\tTest: Average Accuracy: 0.2994902482269504\tAverage Loss: 2.158225793844689\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.3380696961620469\tAverage Loss: 1.9608337281692434\n",
      "\tTest: Average Accuracy: 0.30011081560283687\tAverage Loss: 2.197348263352279\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.34788113006396587\tAverage Loss: 1.9313239310326635\n",
      "\tTest: Average Accuracy: 0.3134751773049645\tAverage Loss: 2.16926136985209\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.34618203624733473\tAverage Loss: 1.9597311212662696\n",
      "\tTest: Average Accuracy: 0.32659574468085106\tAverage Loss: 2.1599935696881944\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.33308901918976547\tAverage Loss: 1.9787888789766557\n",
      "\tTest: Average Accuracy: 0.2646941489361702\tAverage Loss: 2.3291177650698565\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.31008462153518124\tAverage Loss: 2.0366467980106107\n",
      "\tTest: Average Accuracy: 0.2745345744680851\tAverage Loss: 2.2790644447790096\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.24381996268656717\tAverage Loss: 2.225375194933019\n",
      "\tTest: Average Accuracy: 0.18701241134751775\tAverage Loss: 2.481530410502706\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.19456289978678037\tAverage Loss: 2.366796829212928\n",
      "\tTest: Average Accuracy: 0.14366134751773052\tAverage Loss: 2.5894576172171244\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.17220815565031983\tAverage Loss: 2.405179928558101\n",
      "\tTest: Average Accuracy: 0.1434840425531915\tAverage Loss: 2.5636394808511205\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.17758861940298507\tAverage Loss: 2.400457497317353\n",
      "\tTest: Average Accuracy: 0.16041666666666668\tAverage Loss: 2.5157016345231806\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.17122534648187634\tAverage Loss: 2.4014260543356203\n",
      "\tTest: Average Accuracy: 0.13284574468085106\tAverage Loss: 2.539162055275116\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "\n",
    "network.set_training_param(loss=CrossEntropy(), learning_rate=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, there is no progress in the accuracy of the network after many iterations. The reason is that:\n",
    "\n",
    "A learning rate that is too large can cause the model to converge too quickly to a suboptimal solution. If the step size is too large, it can **jump over the minima we are trying to reach**, ie. we **overshoot**. This can lead to osculations around the minimum or in some cases to outright divergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Too Small Learning Rate Impact:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test the network's output with **Learning Rate = 0.0001** which is 10 times less than the previous one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.1841851012793177\tAverage Loss: 2.361480530514004\n",
      "\tTest: Average Accuracy: 0.16879432624113477\tAverage Loss: 2.5106846880457434\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.18933235607675905\tAverage Loss: 2.3502770250815352\n",
      "\tTest: Average Accuracy: 0.16850620567375885\tAverage Loss: 2.508164503696295\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.1886993603411514\tAverage Loss: 2.3453009913181204\n",
      "\tTest: Average Accuracy: 0.16832890070921988\tAverage Loss: 2.504150327926679\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.18779984008528786\tAverage Loss: 2.342110530038092\n",
      "\tTest: Average Accuracy: 0.16892730496453903\tAverage Loss: 2.5023383996468618\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.18746668443496803\tAverage Loss: 2.339914845909795\n",
      "\tTest: Average Accuracy: 0.168395390070922\tAverage Loss: 2.5008977343674017\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.1865671641791045\tAverage Loss: 2.3377774870389274\n",
      "\tTest: Average Accuracy: 0.1674645390070922\tAverage Loss: 2.4998946089482024\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.18606743070362472\tAverage Loss: 2.3360371673238123\n",
      "\tTest: Average Accuracy: 0.16713209219858158\tAverage Loss: 2.499147954085774\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.18585087953091683\tAverage Loss: 2.334204092986124\n",
      "\tTest: Average Accuracy: 0.1662012411347518\tAverage Loss: 2.4981069375116816\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.18565098614072495\tAverage Loss: 2.332406648818986\n",
      "\tTest: Average Accuracy: 0.1657358156028369\tAverage Loss: 2.4974247411664248\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.1857509328358209\tAverage Loss: 2.3309684487061455\n",
      "\tTest: Average Accuracy: 0.16540336879432627\tAverage Loss: 2.4966824540489596\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.18546775053304904\tAverage Loss: 2.329681658709318\n",
      "\tTest: Average Accuracy: 0.16580230496453902\tAverage Loss: 2.4958261198960674\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.1863172974413646\tAverage Loss: 2.3283125737269166\n",
      "\tTest: Average Accuracy: 0.16600177304964542\tAverage Loss: 2.495763248698215\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.18683368869936035\tAverage Loss: 2.326772066156329\n",
      "\tTest: Average Accuracy: 0.16640070921985817\tAverage Loss: 2.4945559310951575\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.18738339552238806\tAverage Loss: 2.3247722801142077\n",
      "\tTest: Average Accuracy: 0.16719858156028372\tAverage Loss: 2.493860972368549\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.18758328891257997\tAverage Loss: 2.3226125321313416\n",
      "\tTest: Average Accuracy: 0.1676640070921986\tAverage Loss: 2.4922842482173317\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.18903251599147122\tAverage Loss: 2.3197687000104215\n",
      "\tTest: Average Accuracy: 0.16932624113475178\tAverage Loss: 2.4906100612415916\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.19113139658848613\tAverage Loss: 2.316285681093657\n",
      "\tTest: Average Accuracy: 0.1707890070921986\tAverage Loss: 2.489101508299035\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.19194762793176973\tAverage Loss: 2.3127208215342727\n",
      "\tTest: Average Accuracy: 0.1717863475177305\tAverage Loss: 2.4865446598759675\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.19366337953091683\tAverage Loss: 2.309114074356049\n",
      "\tTest: Average Accuracy: 0.17371453900709222\tAverage Loss: 2.4840057814261916\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.19762793176972282\tAverage Loss: 2.3046333643978834\n",
      "\tTest: Average Accuracy: 0.17710549645390072\tAverage Loss: 2.4802410466392923\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "network.set_training_param(loss=CrossEntropy(), learning_rate=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A learning rate that is too small may never converge or may **get stuck on a suboptimal solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Activation Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.05525386460554371\tAverage Loss: 2.9531939974952177\n",
      "\tTest: Average Accuracy: 0.05680407801418439\tAverage Loss: 2.9493210938140644\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.056319962686567165\tAverage Loss: 2.950765607043091\n",
      "\tTest: Average Accuracy: 0.07282801418439717\tAverage Loss: 2.949127743140371\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.05655317164179104\tAverage Loss: 2.9505554865720947\n",
      "\tTest: Average Accuracy: 0.065625\tAverage Loss: 2.948948764463147\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.05690298507462686\tAverage Loss: 2.950300252059465\n",
      "\tTest: Average Accuracy: 0.055895390070921994\tAverage Loss: 2.9486907162512574\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.05818563432835821\tAverage Loss: 2.9498180016921207\n",
      "\tTest: Average Accuracy: 0.0581781914893617\tAverage Loss: 2.948132869180893\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.061517190831556504\tAverage Loss: 2.948601627143113\n",
      "\tTest: Average Accuracy: 0.0692154255319149\tAverage Loss: 2.9466286258657\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.07361074093816632\tAverage Loss: 2.944951538958448\n",
      "\tTest: Average Accuracy: 0.07194148936170212\tAverage Loss: 2.9415326126335137\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.10042977078891258\tAverage Loss: 2.9257928869786007\n",
      "\tTest: Average Accuracy: 0.09175531914893617\tAverage Loss: 2.901013293198007\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.113272921108742\tAverage Loss: 2.790239530147834\n",
      "\tTest: Average Accuracy: 0.10738031914893617\tAverage Loss: 2.717643481871939\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.13431170042643922\tAverage Loss: 2.6094594671678606\n",
      "\tTest: Average Accuracy: 0.13743351063829787\tAverage Loss: 2.5914936773874917\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.16477878464818763\tAverage Loss: 2.483375680376434\n",
      "\tTest: Average Accuracy: 0.15319148936170213\tAverage Loss: 2.4917265137864093\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.18774986673773988\tAverage Loss: 2.3821370613669974\n",
      "\tTest: Average Accuracy: 0.17626329787234044\tAverage Loss: 2.423326417667376\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.2060567697228145\tAverage Loss: 2.310822643822161\n",
      "\tTest: Average Accuracy: 0.18665780141843968\tAverage Loss: 2.379233939626567\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.22214818763326227\tAverage Loss: 2.2591365265356282\n",
      "\tTest: Average Accuracy: 0.19694148936170214\tAverage Loss: 2.3486683452926966\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.23893923240938167\tAverage Loss: 2.217563527140043\n",
      "\tTest: Average Accuracy: 0.20842198581560287\tAverage Loss: 2.323159125720623\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.2554804104477612\tAverage Loss: 2.1771739159475363\n",
      "\tTest: Average Accuracy: 0.21899379432624116\tAverage Loss: 2.2947457945938585\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.2875299840085288\tAverage Loss: 2.124688399000886\n",
      "\tTest: Average Accuracy: 0.2562278368794326\tAverage Loss: 2.2437925843886344\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.35592683901918976\tAverage Loss: 2.0266314267353964\n",
      "\tTest: Average Accuracy: 0.3256648936170213\tAverage Loss: 2.1435598463917085\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.39658848614072495\tAverage Loss: 1.8978584633157338\n",
      "\tTest: Average Accuracy: 0.35904255319148937\tAverage Loss: 2.0597561650507963\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.4312533315565032\tAverage Loss: 1.7923307858569237\n",
      "\tTest: Average Accuracy: 0.3917996453900709\tAverage Loss: 1.9942174769178047\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = 784\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "\n",
    "\n",
    "network.add_layer(n_neurons = 16, activation = Sigmoid(), weight_initializer='uniform')\n",
    "\n",
    "network.add_layer(n_neurons = 16, activation = Sigmoid(), weight_initializer='uniform')\n",
    "\n",
    "network.add_layer(n_neurons = 20, activation = Identical(), weight_initializer='uniform')\n",
    "\n",
    "network.set_training_param(loss=CrossEntropy(), learning_rate=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, the **Sigmoid** functino doesn't seem to be giving us good results as **Relu**. The reason is this:\n",
    "\n",
    "The bigger the input (in absolute value) the smaller the gradient of the sigmoid function. But, probably an even more important effect is that the derivative of the sigmoid function is ALWAYS smaller than one. In fact it is at most 0.25! \n",
    "\n",
    "The down side of this is that if you have many layers, you will multiply these gradients, and the product of many smaller than 1 values goes to zero very quickly.\n",
    "\n",
    "Source: https://stats.stackexchange.com/questions/126238/what-are-the-advantages-of-relu-over-sigmoid-function-in-deep-neural-networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperbolic Tangent Activation Function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disadvantages**:\n",
    "\n",
    "1. More computation expensive than sigmoid function.\n",
    "2. Suffers with gradient vanishing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaky Relu Activation Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.16254664179104478\tAverage Loss: 2.594992643012774\n",
      "\tTest: Average Accuracy: 0.25511968085106385\tAverage Loss: 2.271591664962809\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.48012726545842216\tAverage Loss: 1.7236395645115818\n",
      "\tTest: Average Accuracy: 0.49406028368794325\tAverage Loss: 1.730029276453238\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.6610474413646056\tAverage Loss: 1.1555360130784045\n",
      "\tTest: Average Accuracy: 0.5984264184397162\tAverage Loss: 1.3678372519123372\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.7344582889125799\tAverage Loss: 0.9276454432124895\n",
      "\tTest: Average Accuracy: 0.6547207446808511\tAverage Loss: 1.205069887228231\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.7730710287846482\tAverage Loss: 0.7966147990379857\n",
      "\tTest: Average Accuracy: 0.6838652482269503\tAverage Loss: 1.1223586259621654\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.7952258795309168\tAverage Loss: 0.7239457455057218\n",
      "\tTest: Average Accuracy: 0.6975398936170213\tAverage Loss: 1.080581001978909\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.8086853678038379\tAverage Loss: 0.680042374811289\n",
      "\tTest: Average Accuracy: 0.7084441489361702\tAverage Loss: 1.0515657878993196\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.8158482142857143\tAverage Loss: 0.6506719479312408\n",
      "\tTest: Average Accuracy: 0.7153590425531915\tAverage Loss: 1.030843418341667\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.8220115938166311\tAverage Loss: 0.6289453183931417\n",
      "\tTest: Average Accuracy: 0.7205452127659574\tAverage Loss: 1.0155949596988203\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.8270922174840085\tAverage Loss: 0.6123835209033982\n",
      "\tTest: Average Accuracy: 0.7237810283687944\tAverage Loss: 1.0092811558110597\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.8295242537313433\tAverage Loss: 0.5993408722008813\n",
      "\tTest: Average Accuracy: 0.7247562056737588\tAverage Loss: 1.0040186555545754\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.8336886993603412\tAverage Loss: 0.5877423032261307\n",
      "\tTest: Average Accuracy: 0.726950354609929\tAverage Loss: 1.0003896529709901\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.8358542110874201\tAverage Loss: 0.5782184863730454\n",
      "\tTest: Average Accuracy: 0.7265957446808511\tAverage Loss: 0.9957236611950635\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.837886460554371\tAverage Loss: 0.5699046019045267\n",
      "\tTest: Average Accuracy: 0.727593085106383\tAverage Loss: 0.9925659726996736\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.839868736673774\tAverage Loss: 0.5624127116432812\n",
      "\tTest: Average Accuracy: 0.7314494680851064\tAverage Loss: 0.9870099717365329\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.841801039445629\tAverage Loss: 0.5560187222949191\n",
      "\tTest: Average Accuracy: 0.7309618794326241\tAverage Loss: 0.9813653777874669\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.843799973347548\tAverage Loss: 0.5499533081145102\n",
      "\tTest: Average Accuracy: 0.7309175531914893\tAverage Loss: 0.9826250390321769\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.8450493070362474\tAverage Loss: 0.5447899904238309\n",
      "\tTest: Average Accuracy: 0.7325132978723404\tAverage Loss: 0.9809690975397921\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.8464319029850746\tAverage Loss: 0.5399378922661611\n",
      "\tTest: Average Accuracy: 0.7335328014184397\tAverage Loss: 0.9797267109421992\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.8478644722814499\tAverage Loss: 0.5357850727565338\n",
      "\tTest: Average Accuracy: 0.7334219858156029\tAverage Loss: 0.9802072732351157\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = 784\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "\n",
    "\n",
    "network.add_layer(n_neurons = 16, activation = LeakyRelu(), weight_initializer='uniform')\n",
    "\n",
    "network.add_layer(n_neurons = 16, activation = LeakyRelu(), weight_initializer='uniform')\n",
    "\n",
    "network.add_layer(n_neurons = 20, activation = Identical(), weight_initializer='uniform')\n",
    "\n",
    "network.set_training_param(loss=CrossEntropy(), learning_rate=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaky ReLU has two benefits over ReLU:\n",
    "\n",
    "1. It fixes the **“dying ReLU” problem** (ReLU neurons become inactive and only output 0 for any input), as it doesn’t have zero-slope parts\n",
    "2. It speeds up training. There is evidence that having the “mean activation” be close to 0 makes training faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Size Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try 3 batch sizes other than 64 here:\n",
    "1. 16\n",
    "2. 32\n",
    "3. 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "TRAINLOADER = Dataloader(data = train_images_df.values.tolist(), labels = train_labels_df.values.tolist(), n_classes = 20, batch_size = BATCH_SIZE, shuffle = False)\n",
    "TESTLOADER = Dataloader(data = test_images_df.values.tolist(), labels = test_labels_df.values.tolist(), n_classes = 20, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.15493333333333334\tAverage Loss: 2.6329516675776987\n",
      "\tTest: Average Accuracy: 0.25086620469083154\tAverage Loss: 2.3018383961687805\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.5148\tAverage Loss: 1.6003441532465144\n",
      "\tTest: Average Accuracy: 0.533382196162047\tAverage Loss: 1.6156920126775847\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.68375\tAverage Loss: 1.0968698186807184\n",
      "\tTest: Average Accuracy: 0.6114738805970149\tAverage Loss: 1.357388674338265\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.7380666666666666\tAverage Loss: 0.9204536410952932\n",
      "\tTest: Average Accuracy: 0.6487206823027718\tAverage Loss: 1.2339844745734145\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.7690333333333333\tAverage Loss: 0.8147986511096688\n",
      "\tTest: Average Accuracy: 0.6770389125799574\tAverage Loss: 1.1540195543726666\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.79015\tAverage Loss: 0.7425502521590184\n",
      "\tTest: Average Accuracy: 0.695362473347548\tAverage Loss: 1.097732588645471\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.8040333333333334\tAverage Loss: 0.6929311956958275\n",
      "\tTest: Average Accuracy: 0.7044243070362474\tAverage Loss: 1.0685366111844614\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.8132333333333334\tAverage Loss: 0.6578344647310281\n",
      "\tTest: Average Accuracy: 0.7093550106609808\tAverage Loss: 1.049234853571339\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.8199666666666666\tAverage Loss: 0.6329254368128441\n",
      "\tTest: Average Accuracy: 0.7142190831556503\tAverage Loss: 1.0340311073138937\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.8254666666666667\tAverage Loss: 0.6127778167179897\n",
      "\tTest: Average Accuracy: 0.7173507462686567\tAverage Loss: 1.0234366370476322\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.8309\tAverage Loss: 0.5965300382833979\n",
      "\tTest: Average Accuracy: 0.72261460554371\tAverage Loss: 1.0105357718161374\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.83435\tAverage Loss: 0.5829580264235708\n",
      "\tTest: Average Accuracy: 0.7263459488272921\tAverage Loss: 0.9960234574402016\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.8372833333333334\tAverage Loss: 0.5715340734105891\n",
      "\tTest: Average Accuracy: 0.7286780383795309\tAverage Loss: 0.9867047965921799\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.8400166666666666\tAverage Loss: 0.5621118667995827\n",
      "\tTest: Average Accuracy: 0.7310767590618337\tAverage Loss: 0.9792710969817926\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.8416333333333333\tAverage Loss: 0.5539414560860955\n",
      "\tTest: Average Accuracy: 0.7327425373134329\tAverage Loss: 0.9760608969362182\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.8434833333333334\tAverage Loss: 0.5466195936728927\n",
      "\tTest: Average Accuracy: 0.7336087420042644\tAverage Loss: 0.972259777876713\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.84485\tAverage Loss: 0.5402921290116937\n",
      "\tTest: Average Accuracy: 0.7342084221748401\tAverage Loss: 0.9687588666728233\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.84675\tAverage Loss: 0.5346067851219876\n",
      "\tTest: Average Accuracy: 0.7365405117270789\tAverage Loss: 0.9652330962148652\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.8483166666666667\tAverage Loss: 0.5296499372351182\n",
      "\tTest: Average Accuracy: 0.7384728144989339\tAverage Loss: 0.9642987734243859\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.84965\tAverage Loss: 0.524970452253477\n",
      "\tTest: Average Accuracy: 0.7402052238805971\tAverage Loss: 0.9648394451890184\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = 784\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "\n",
    "\n",
    "network.add_layer(n_neurons = 16, activation = Relu(), weight_initializer='uniform')\n",
    "\n",
    "network.add_layer(n_neurons = 16, activation = Relu(), weight_initializer='uniform')\n",
    "\n",
    "network.add_layer(n_neurons = 20, activation = Identical(), weight_initializer='uniform')\n",
    "\n",
    "network.set_training_param(loss=CrossEntropy(), learning_rate=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "TRAINLOADER = Dataloader(data = train_images_df.values.tolist(), labels = train_labels_df.values.tolist(), n_classes = 20, batch_size = BATCH_SIZE, shuffle = False)\n",
    "TESTLOADER = Dataloader(data = test_images_df.values.tolist(), labels = test_labels_df.values.tolist(), n_classes = 20, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.16406666666666667\tAverage Loss: 2.588016563203567\n",
      "\tTest: Average Accuracy: 0.25224324804548687\tAverage Loss: 2.27489944917599\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.4942666666666667\tAverage Loss: 1.6581054007466074\n",
      "\tTest: Average Accuracy: 0.49904495380241654\tAverage Loss: 1.7133881649132796\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.6545666666666666\tAverage Loss: 1.1823671884471836\n",
      "\tTest: Average Accuracy: 0.5965929282160625\tAverage Loss: 1.3902505564214616\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.7289833333333333\tAverage Loss: 0.9535431850902056\n",
      "\tTest: Average Accuracy: 0.6440787135749823\tAverage Loss: 1.2464486022718402\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.7691333333333333\tAverage Loss: 0.8197527831200714\n",
      "\tTest: Average Accuracy: 0.6746624022743426\tAverage Loss: 1.1473077753093524\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.7933333333333333\tAverage Loss: 0.7433894973401992\n",
      "\tTest: Average Accuracy: 0.685723169864961\tAverage Loss: 1.1100895217875657\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.80585\tAverage Loss: 0.696065295402814\n",
      "\tTest: Average Accuracy: 0.6989161336176262\tAverage Loss: 1.084705041526891\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.81365\tAverage Loss: 0.6645547281421526\n",
      "\tTest: Average Accuracy: 0.7042910447761194\tAverage Loss: 1.0649445312960943\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.8204333333333333\tAverage Loss: 0.6403208167185578\n",
      "\tTest: Average Accuracy: 0.7106210021321961\tAverage Loss: 1.0486720700429557\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.8259\tAverage Loss: 0.6197749815327749\n",
      "\tTest: Average Accuracy: 0.7138415067519546\tAverage Loss: 1.0354832426407874\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.8301\tAverage Loss: 0.6031976582237975\n",
      "\tTest: Average Accuracy: 0.718727789623312\tAverage Loss: 1.030586436960604\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.8341666666666666\tAverage Loss: 0.5899857135751378\n",
      "\tTest: Average Accuracy: 0.7193941009239516\tAverage Loss: 1.0228380543404276\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.8374\tAverage Loss: 0.5786464935106682\n",
      "\tTest: Average Accuracy: 0.7233919687277895\tAverage Loss: 1.0147309230982464\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.8404666666666667\tAverage Loss: 0.569354298795661\n",
      "\tTest: Average Accuracy: 0.7249911158493247\tAverage Loss: 1.0105695573404456\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.8425\tAverage Loss: 0.5613974260657766\n",
      "\tTest: Average Accuracy: 0.7266568941009239\tAverage Loss: 1.00570663292387\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.8440333333333333\tAverage Loss: 0.5540667787757027\n",
      "\tTest: Average Accuracy: 0.7285891968727789\tAverage Loss: 1.002371419056094\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.8452333333333333\tAverage Loss: 0.547790278190825\n",
      "\tTest: Average Accuracy: 0.7309212864250177\tAverage Loss: 0.9991823159359295\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.8472333333333333\tAverage Loss: 0.5418765298851469\n",
      "\tTest: Average Accuracy: 0.7305881307746979\tAverage Loss: 1.0004391354893818\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.8486666666666667\tAverage Loss: 0.5368260335463043\n",
      "\tTest: Average Accuracy: 0.7309434968017058\tAverage Loss: 0.9997775746988399\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.84925\tAverage Loss: 0.5323890126912211\n",
      "\tTest: Average Accuracy: 0.7300106609808102\tAverage Loss: 1.0018965346162878\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = 784\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "\n",
    "\n",
    "network.add_layer(n_neurons = 16, activation = Relu(), weight_initializer='uniform')\n",
    "\n",
    "network.add_layer(n_neurons = 16, activation = Relu(), weight_initializer='uniform')\n",
    "\n",
    "network.add_layer(n_neurons = 20, activation = Identical(), weight_initializer='uniform')\n",
    "\n",
    "network.set_training_param(loss=CrossEntropy(), learning_rate=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "TRAINLOADER = Dataloader(data = train_images_df.values.tolist(), labels = train_labels_df.values.tolist(), n_classes = 20, batch_size = BATCH_SIZE, shuffle = False)\n",
    "TESTLOADER = Dataloader(data = test_images_df.values.tolist(), labels = test_labels_df.values.tolist(), n_classes = 20, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.13274601063829788\tAverage Loss: 2.6941009523360275\n",
      "\tTest: Average Accuracy: 0.21623062555753791\tAverage Loss: 2.4399860213342497\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.4373005319148936\tAverage Loss: 1.8102087597717935\n",
      "\tTest: Average Accuracy: 0.4962052575825156\tAverage Loss: 1.7164040538034446\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.655324689716312\tAverage Loss: 1.1827278614583197\n",
      "\tTest: Average Accuracy: 0.5984054415700268\tAverage Loss: 1.363571384915894\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.7216312056737588\tAverage Loss: 0.9603960976961776\n",
      "\tTest: Average Accuracy: 0.644053858162355\tAverage Loss: 1.2375546476884722\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.7534962322695035\tAverage Loss: 0.8493931179492823\n",
      "\tTest: Average Accuracy: 0.6652193911685995\tAverage Loss: 1.1692851125917092\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.7734208776595745\tAverage Loss: 0.7790940651681582\n",
      "\tTest: Average Accuracy: 0.6823985280999109\tAverage Loss: 1.1191591772314902\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.7885472074468085\tAverage Loss: 0.7305738166240557\n",
      "\tTest: Average Accuracy: 0.6916153267172167\tAverage Loss: 1.0928439999767086\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.7997229609929077\tAverage Loss: 0.6925086203744175\n",
      "\tTest: Average Accuracy: 0.7002920104817127\tAverage Loss: 1.0680361232892701\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.808416445035461\tAverage Loss: 0.6622857358722646\n",
      "\tTest: Average Accuracy: 0.7057454281891169\tAverage Loss: 1.0490540968233169\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.8150820035460992\tAverage Loss: 0.6386935485444977\n",
      "\tTest: Average Accuracy: 0.7119062221231044\tAverage Loss: 1.0338167341602489\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.8213929521276596\tAverage Loss: 0.6184433169680008\n",
      "\tTest: Average Accuracy: 0.7181750390276539\tAverage Loss: 1.0209627132409482\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.8265403368794327\tAverage Loss: 0.603275921388963\n",
      "\tTest: Average Accuracy: 0.7214401204281891\tAverage Loss: 1.0127630346228718\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.8300975177304966\tAverage Loss: 0.5906343845881844\n",
      "\tTest: Average Accuracy: 0.7232939339875112\tAverage Loss: 1.0066141853516528\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.8331061613475178\tAverage Loss: 0.5793618580966016\n",
      "\tTest: Average Accuracy: 0.723935102586976\tAverage Loss: 1.0045903087860533\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.8354222074468085\tAverage Loss: 0.5704714834831773\n",
      "\tTest: Average Accuracy: 0.7252348628456735\tAverage Loss: 1.0024420534460319\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.8374889184397162\tAverage Loss: 0.5622101205684591\n",
      "\tTest: Average Accuracy: 0.7247052018287244\tAverage Loss: 0.9986733838123322\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.8395833333333332\tAverage Loss: 0.5552061556568687\n",
      "\tTest: Average Accuracy: 0.7272001839875112\tAverage Loss: 0.9992698761227276\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.8411125886524822\tAverage Loss: 0.5488929388755582\n",
      "\tTest: Average Accuracy: 0.7301795272078502\tAverage Loss: 0.9928875885617242\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.8427526595744681\tAverage Loss: 0.5428074160329269\n",
      "\tTest: Average Accuracy: 0.7311517339429082\tAverage Loss: 0.9938688477897875\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.8440492021276595\tAverage Loss: 0.5378573471853875\n",
      "\tTest: Average Accuracy: 0.7308869034344336\tAverage Loss: 0.9915487783581796\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = 784\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "\n",
    "\n",
    "network.add_layer(n_neurons = 16, activation = Relu(), weight_initializer='uniform')\n",
    "\n",
    "network.add_layer(n_neurons = 16, activation = Relu(), weight_initializer='uniform')\n",
    "\n",
    "network.add_layer(n_neurons = 20, activation = Identical(), weight_initializer='uniform')\n",
    "\n",
    "network.set_training_param(loss=CrossEntropy(), learning_rate=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **smaller batch size**, increases the number of forward/backward propagations, leading to a **slower neural network**. Also it leads to a **higher variance**, due to smaller number of training samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why use batches?\n",
    "\n",
    "It requires **less memory**. Since you train the network using fewer samples, the overall training procedure requires less memory. That's especially important if you are not able to fit the whole dataset in your machine's memory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why use multiple epochs?\n",
    "\n",
    "We are using a limited dataset and to optimise the learning and the graph we are using Gradient Descent which is an iterative process. So, updating the weights with single pass or one epoch is not enough. \n",
    "\n",
    "As the number of epochs increases, more number of times the weight are changed in the neural network and the curve goes from **underfitting** to optimal to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "TRAINLOADER = Dataloader(data = train_images_df.values.tolist(), labels = train_labels_df.values.tolist(), n_classes = 20, batch_size = BATCH_SIZE, shuffle = False)\n",
    "TESTLOADER = Dataloader(data = test_images_df.values.tolist(), labels = test_labels_df.values.tolist(), n_classes = 20, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.15538379530916843\tAverage Loss: 2.613205540369536\n",
      "\tTest: Average Accuracy: 0.20675975177304967\tAverage Loss: 2.3691979760689352\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.45973813965884863\tAverage Loss: 1.7479405828664443\n",
      "\tTest: Average Accuracy: 0.5026595744680851\tAverage Loss: 1.7294776818094195\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.6551672441364605\tAverage Loss: 1.1864285393728937\n",
      "\tTest: Average Accuracy: 0.5914228723404256\tAverage Loss: 1.428925255495158\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.7271788379530917\tAverage Loss: 0.9599695854615322\n",
      "\tTest: Average Accuracy: 0.6405806737588652\tAverage Loss: 1.2724313609379878\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.7680903518123667\tAverage Loss: 0.8223274776587995\n",
      "\tTest: Average Accuracy: 0.6755762411347519\tAverage Loss: 1.1594483721421125\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.7902618603411514\tAverage Loss: 0.7422030001975517\n",
      "\tTest: Average Accuracy: 0.6960771276595744\tAverage Loss: 1.0990526385270314\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.8023387526652452\tAverage Loss: 0.6955619478549767\n",
      "\tTest: Average Accuracy: 0.7058289007092199\tAverage Loss: 1.069738850025173\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.8117503997867804\tAverage Loss: 0.6643186423268646\n",
      "\tTest: Average Accuracy: 0.7110372340425531\tAverage Loss: 1.0460691297258888\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.818530117270789\tAverage Loss: 0.6406450774303983\n",
      "\tTest: Average Accuracy: 0.7193705673758864\tAverage Loss: 1.0231237700837421\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.8231776385927505\tAverage Loss: 0.6221609828018052\n",
      "\tTest: Average Accuracy: 0.7245567375886524\tAverage Loss: 1.008924099047564\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.8264925373134329\tAverage Loss: 0.6067070387652302\n",
      "\tTest: Average Accuracy: 0.7261968085106383\tAverage Loss: 1.0032115346326775\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.8312233475479744\tAverage Loss: 0.5934833917347196\n",
      "\tTest: Average Accuracy: 0.7294104609929077\tAverage Loss: 0.9949507665877406\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.8344549573560768\tAverage Loss: 0.5819372645226406\n",
      "\tTest: Average Accuracy: 0.7308067375886524\tAverage Loss: 0.9922583682919116\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.8368037046908315\tAverage Loss: 0.572397907387995\n",
      "\tTest: Average Accuracy: 0.7322695035460992\tAverage Loss: 0.9898394116239654\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.8394356343283582\tAverage Loss: 0.564131855468781\n",
      "\tTest: Average Accuracy: 0.7334219858156029\tAverage Loss: 0.9875335689213849\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.841917643923241\tAverage Loss: 0.556718675554136\n",
      "\tTest: Average Accuracy: 0.7348847517730497\tAverage Loss: 0.9851208763718841\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.8435834221748401\tAverage Loss: 0.5502871559032342\n",
      "\tTest: Average Accuracy: 0.73479609929078\tAverage Loss: 0.9849793669420607\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.8446162046908315\tAverage Loss: 0.544579947239066\n",
      "\tTest: Average Accuracy: 0.7357269503546099\tAverage Loss: 0.9805140906678764\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.8462986407249466\tAverage Loss: 0.5390680773888251\n",
      "\tTest: Average Accuracy: 0.7349290780141843\tAverage Loss: 0.9784061180236526\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.8468650053304904\tAverage Loss: 0.5342525347427125\n",
      "\tTest: Average Accuracy: 0.734729609929078\tAverage Loss: 0.978193824326239\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = 784\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "\n",
    "\n",
    "network.add_layer(n_neurons = 16, activation = Relu(), weight_initializer='uniform')\n",
    "\n",
    "network.add_layer(n_neurons = 16, activation = Relu(), weight_initializer='uniform')\n",
    "\n",
    "network.add_layer(n_neurons = 20, activation = Identical(), weight_initializer='uniform')\n",
    "\n",
    "network.set_training_param(loss=CrossEntropy(), learning_rate=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_accuracy': [0.15538379530916843, 0.45973813965884863, 0.6551672441364605, 0.7271788379530917, 0.7680903518123667, 0.7902618603411514, 0.8023387526652452, 0.8117503997867804, 0.818530117270789, 0.8231776385927505, 0.8264925373134329, 0.8312233475479744, 0.8344549573560768, 0.8368037046908315, 0.8394356343283582, 0.841917643923241, 0.8435834221748401, 0.8446162046908315, 0.8462986407249466, 0.8468650053304904], 'train_loss': [2.613205540369536, 1.7479405828664443, 1.1864285393728937, 0.9599695854615322, 0.8223274776587995, 0.7422030001975517, 0.6955619478549767, 0.6643186423268646, 0.6406450774303983, 0.6221609828018052, 0.6067070387652302, 0.5934833917347196, 0.5819372645226406, 0.572397907387995, 0.564131855468781, 0.556718675554136, 0.5502871559032342, 0.544579947239066, 0.5390680773888251, 0.5342525347427125], 'test_accuracy': [0.20675975177304967, 0.5026595744680851, 0.5914228723404256, 0.6405806737588652, 0.6755762411347519, 0.6960771276595744, 0.7058289007092199, 0.7110372340425531, 0.7193705673758864, 0.7245567375886524, 0.7261968085106383, 0.7294104609929077, 0.7308067375886524, 0.7322695035460992, 0.7334219858156029, 0.7348847517730497, 0.73479609929078, 0.7357269503546099, 0.7349290780141843, 0.734729609929078], 'test_loss': [2.3691979760689352, 1.7294776818094195, 1.428925255495158, 1.2724313609379878, 1.1594483721421125, 1.0990526385270314, 1.069738850025173, 1.0460691297258888, 1.0231237700837421, 1.008924099047564, 1.0032115346326775, 0.9949507665877406, 0.9922583682919116, 0.9898394116239654, 0.9875335689213849, 0.9851208763718841, 0.9849793669420607, 0.9805140906678764, 0.9784061180236526, 0.978193824326239]}\n"
     ]
    }
   ],
   "source": [
    "print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff64aab5c50>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_acc_plt, = plt.plot(log['train_accuracy'], label=\"Train Accuracy\")\n",
    "test_acc_plt, = plt.plot(log['test_accuracy'], label=\"Test Accuracy\")\n",
    "plt.legend(handles = [train_acc_plt, test_acc_plt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the number of epochs increases, it will reach a point where it starts to perform better on train data in compare to test data. \n",
    "\n",
    "This is the point when we say the model has started **overfitting** the train data. \n",
    "\n",
    "Therefore, it is better to limit the number of epochs to a certain number to prevent overfitting. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
